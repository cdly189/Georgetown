---
title: "656 | Data Mining, Project 1"
output:
  html_document: default
  word_document: default
  pdf_document: default
---
We will start the R code with one of the most important steps, which is data cleaning. Without clean data, our models wouldn't perform as well (or at all) and we would have lower accuracy. Thus, cleaning is a key first step.

```{r}
# Read the data set into R
#data <- read.csv("/Users/rogerlo/Desktop/Math656_Data_Mining/HWs/Midterm_Datathon_Competition/PIAAC_US_2012_subsample.csv")
data <- read.csv("C:\\Users\\lahenderson\\Documents\\Gtown - MAST\\656\\Project1\\PIAAC_US_2012_subsample.csv")

# Inspect the structure of the data such as to see whether columns are numerical or character
str(data)

# Select only numeric variables. 
num_cols <- unlist(lapply(data, is.numeric))
data_num <- data[,num_cols]    # 555 variables 

# Separate PS_class because 0 means below 1 level
# While 0 in other columns means missing values
# We separate to replace NA values and combine the two data frame later
PS_class <- data_num[,ncol(data_num)]
data_num <- data_num[,2:554]    # Exclude SEQID

# Convert select values to NA
values <- c(0,6,7,8,9,96,97,98,99,996,997,998,999,9996,9997,9998,9999,999999999996,
            999999999997,999999999998,999999999999,99999999996,99999999999)    

# Replace all the missing values with NA
library(naniar)
data_replace_na <- data_num %>% replace_with_na_all(condition = ~.x %in% c(values))

# Remove columns with more than 20% NA
data_remove_na <- data_replace_na[, which(colMeans(!is.na(data_replace_na)) > 0.2)]

# Fill in the missing values with the mean values
library(imputeTS)
data_new <- na_mean(data_remove_na)

# Combine the cleaned data set with the PS_Class variable
data_new <- cbind(data_new,PS_class)

#rename data to df
df<-data_new

#Ensure gold standard is a factor
df$PS_class=as.factor(df$PS_class)

#confirm class is dataframe
#class(df)

# Export the file
library(writexl)
write_xlsx(data_new,'clean_data_updated.xlsx')
```

This code details our Random Forest, KNN, & Naive Bayes models after having cleaned the data. We will
use the Caret package to make the classification and conduct the training.

```{r}
#load packages
library(ggplot2)
library(lattice)
library(caret)
library(dplyr)
library(tidyverse)
library(mlbench)
```


#Set Up Training & Test Set for Random Forest
Training data takes 80% (p=0.8). Test data (20%) is not used in the model build until we test after model is built. We do a fixed sampling scheme (10-folds) so we can compare to fitted models later.

```{r}
#make this example reproducible
set.seed(8)

#partition data into train & test for Random Forest
inTrain <- createDataPartition(y=df$PS_class,p=0.8,list=FALSE)
df_train<-df%>%slice(inTrain)
df_test<-df %>%slice(-inTrain)
train_index<-createFolds(df_train$PS_class,k=10) #10 fold inner loop cross-validation

```

# Random Forest model 1 Training of Data
```{r}
#RF Algorithm- Model 1- Train Data
randomForestFit <- df_train %>% train(PS_class ~ .,
  method = "rf",
  data = .,
    tuneLength = 365,#365 is best tunelength tested
    trControl = trainControl(method = "cv", indexOut = train_index))
randomForestFit
```

Then we want to make a prediction using the test data we set aside earlier.

```{r}
#show prediction output for RF model
pr_rf <- predict(randomForestFit, df_test)
pr_rf
```

Next we check confusion matrix between prediction and actual type (gold standard) in the test set.
```{r}
#confusion matrix
confusionMatrix(pr_rf, reference = df_test$PS_class)
confusionMatrix(pr_rf, reference = df_test$PS_class, mode = "prec_recall")
```

### Rank features by importance (LVQ)
```{r}
# prepare training scheme
control <- trainControl(method="repeatedcv", number=10, repeats=3)
# train the model
model <- train(PS_class~., data=df, method="lvq", preProcess="scale", trControl=control)
# estimate variable importance
importance <- varImp(model, scale=FALSE)

# summarize importance, create data frame, and order importance data
str(varImp(model)$importance)
imps <- as.matrix(varImp(model)$importance)
imps <- as.data.frame(imps)
imps$x_mean <- apply(imps,1,mean)
imps <- imps[order(imps[,5], decreasing = TRUE), ]  # Order data descending

#print importance
print(imps)

# plot importance
barplot(imps[1:20,5],xlab = "Attributes", ylab = "Importance")
```




## Iterate Through Top Features for Feature Selection (Top 31)
We chose these features by referencing the importance plot by LVQ
```{r}
#create data subset
data_subset <-data.frame(df$PVLIT1,df$PVNUM1,df$PS2_u02_time_on_task,df$PS2_u07_num_of_diff_visited_pages,df$PS1_u04a_time_on_task,df$PS2_u07_num_of_page_visits,df$PS1_u01b_num_of_email_views,df$PS2_u02_num_of_diff_emails_views,df$PS1_u06b_num_of_page_visits,df$U07x000A,df$PS1_u01b_num_of_diff_emails_views,df$U06b000A,df$PS1_u01a_num_of_diff_emails_views,df$PS1_u01a_num_of_email_views,df$PS2_u07_time_on_task,df$PS2_u23_time_on_task,df$U02x000A,df$U01b000A,df$PS2_u11b_time_on_task,df$PS1_u01b_time_on_task,df$PS2_u19b_time_on_task,df$U03a000A,df$PS2_u16_time_on_task,df$PS1_u06b_time_on_task,df$B_Q01a,df$PS2_u19a_first_interaction_time,df$PS1_u01a_first_interaction_time,df$PS2_u23_num_of_email_views,df$PS1_u03a_time_on_task,df$PS1_u06b_num_of_diff_visited_pages,df$PS2_u23_num_of_page_visits,df$PS_class)
```




#Here, we are using select features and inputting to random forest
#Set Up Training & Test Set for Random Forest
Training data takes 80% (p=0.8). Test data (20%) is not used in the model build until model is built. We do a fixed sampling scheme (10-folds) so we can compare to fitted models later.

```{r}
#make this example reproducible
set.seed(10) # set an arbitrary number to make a reproducible outputs

#partition data
inTrain_small <- createDataPartition(y=data_subset$df.PS_class,p=0.8,list=FALSE)
df_train_small<-data_subset%>%slice(inTrain_small)
df_test_small<-data_subset%>%slice(-inTrain_small)
train_index_small<-createFolds(df_train_small$df.PS_class,k=10) #10 fold inner loop cross-validation

```

# Random Forest with LVQ Feature Selection
```{r}
#Random Forest train data with LVQ Feature Selection
randomForestFit <- df_train_small %>% train(df.PS_class ~ .,
  method = "rf",
  data = .,
    tuneLength = 100,#more is equal or better accuracy, but slower training
    trControl = trainControl(method = "cv", indexOut = train_index_small))
randomForestFit
```


Then we want to make a prediction using the test data we set aside earlier.

```{r}
#prediction
pr_rf <- predict(randomForestFit, df_test_small)
pr_rf
```



Next we check confusion matrix between prediction and actual type (gold standard) in the test set.
```{r}
#check confusion matrix
confusionMatrix(pr_rf, reference = df_test_small$df.PS_class)
confusionMatrix(pr_rf, reference = df_test_small$df.PS_class, mode = "prec_recall")
```

#Set Up Training & Test Set for KNN & Naive Bayes
Training data takes 80% (p=0.8). Test data (20%) is not used in the model build until we test after model is built. We do a fixed sampling scheme (10-folds) so we can compare to fitted models later.

```{r}
#make this example reproducible
set.seed(7)

#partition data for Naive Bayes & KNN
inTrain_small <- createDataPartition(y=data_subset$df.PS_class,p=0.8,list=FALSE)
df_train_small<-data_subset%>%slice(inTrain_small)
df_test_small<-data_subset%>%slice(-inTrain_small)
train_index_small<-createFolds(df_train_small$df.PS_class,k=10) #10 fold inner loop cross-validation

```

# Naive Bayes Classifier
First we train the data.
```{r}
#Naive Bayes Training with Data
nbFit <- df_train_small %>% train(df.PS_class ~ .,
  method = "nb",
  data = .,
  tuneLength = 5,
  trControl = trainControl(method = "cv", indexOut = train_index_small))
nbFit
```
Now having finished training the Naive Bayes model, we predict on the test data.

```{r}
#predict using Naive Bayes trained Model
pr_NB<-predict(nbFit,df_test_small)
pr_NB
```
Now we check the confusion matrix between prediction and actual type (gold standard) in the test set.

```{r}
confusionMatrix(pr_NB,reference=df_test_small$df.PS_class)
```

# KNN classifier Model
First we train the data for the K-NN classifier model.
```{r}
#Train KNN model with the Data
knnFit <- df_train_small %>% train(df.PS_class ~ .,
  method="knn",
  data= .,
  preProcess= "scale",
    tuneLength=5,
  tuneGrid=data.frame(k=1:10),
    trControl=trainControl(method= "cv",indexOut=
train_index_small))
knnFit
```

With model trained, we now use test data to predict.
```{r}
#KNN prediction
pr_KNN<-predict(knnFit,df_test_small)
pr_KNN

```

Next we create the confusion matrix between prediction and actual (gold standard) in the test set.
```{r}
#make confusion matrix
confusionMatrix(pr_KNN,reference=df_test_small$df.PS_class)
```


# Model Evaluation
compare the models performance: Naive Bayes, KNN, and Random Forest

```{r}
#compare models
resamps <- resamples(list(
  naiveBayes=nbFit,
  KNN=knnFit,
  randomForest = randomForestFit
    ))
resamps
```

Finally we calculate summary statistics

```{r}
#show summary of 10-fold resample distribution
summary(resamps)

# MICE Package (for missing data)

# Read the data set into R
#data <- read.csv("/Users/rogerlo/Desktop/Math656_Data_Mining/HWs/Midterm_Datathon_Competition/PIAAC_US_2012_subsample.csv")
data <- read.csv("C:\\Users\\lahenderson\\Documents\\Gtown - MAST\\656\\Project1\\PIAAC_US_2012_subsample.csv")

```

##Perform Mice Transformations
```{r}
# Inspect the data- to see whether they are numerical or character
str(data)
sum(is.na(data))

# Select only numeric variables and confirm sum of N/As 
num_cols <- unlist(lapply(data, is.numeric))
data_num <- data[,num_cols]    # 555 variables 
sum(is.na(data_num))

# Separate PS_class because 0 means below 1 level
PS_class <- data_num[,ncol(data_num)]
data_num <- data_num[,2:554]    # Exclude SEQID

# Convert missing values (9,99,999, etc) to NA
# These numbers represent missing values
values <- c(0,6,7,8,9,96,97,98,99,996,997,998,999,9996,9997,9998,9999,999999999996,
            999999999997,999999999998,999999999999,99999999996,99999999999,' ')    

# Replace all the missing values with NA
library(naniar)
data_replace_na <- data_num %>% replace_with_na_all(condition = ~.x %in% c(values))

# Remove columns with more than 20% NA
data_remove_na <- data_replace_na[, which(colMeans(!is.na(data_replace_na)) > 0.2)]

# Fill in the missing values with MICE package
library(imputeTS)

#load mice package
library(mice)

#apply mice package, cbind in PS_class, & perform the other transformations
md.pattern(data_remove_na)
imputeData <- mice(data_remove_na,m=2,maxit=2,meth='cart',seed=500)
completedData <- complete(imputeData,1)
completeData <- cbind(completedData,PS_class)

sum(is.na(completeData))
colSums(is.na(completeData))
which(colSums(is.na(completeData))>0)
names(which(colSums(is.na(completeData))>0))

#drop columns
drop <- c("B_Q01a","B_Q04a","B_Q05c_T","B_Q20a","B_Q26a_T","C_Q01c","C_Q06",
          "D_Q10_T","H_Q04a","I_Q08_T","J_Q01_T1","J_Q06b_T","J_Q07a_T","J_Q07b_T",
          "YRSQUAL_T","NATIVELANG","HOMLANG","IMYRS_C","EDCAT8","EDCAT7","FE12",
          "AETPOP","FAET12","FAET12JR","NFE12","NFEHRSNJR","NFEHRSJR","PAIDWORK12",
          "ISCO1C","ISCO2C","ISCO2L","NFE12JR","FNFAET12JR","FNFAET12NJR","G_Q04_T")

completeData= completeData[,!(names(completeData) %in% drop)]

#assign to correct df
df<-completeData

#output Excel file
#library(writexl)
#write_xlsx(completeData,'clean_data_updated.xlsx')
```

##Set Up Training & Test Set for Random Forest using MICE package
Training data takes 80% (p=0.8). Test data (20%) is not used in the model build until we test after model is built. We do a fixed sampling scheme (10-folds) so we can compare to fitted models later.

```{r}
#make this example reproducible
set.seed(8)

#partition data into train & test for Random Forest
inTrain <- createDataPartition(y=df$PS_class,p=0.8,list=FALSE)
df_train<-df%>%slice(inTrain)
df_test<-df %>%slice(-inTrain)
train_index<-createFolds(df_train$PS_class,k=10) #10 fold inner loop cross-validation

```

# Random Forest model
```{r}
#Train Random Forest
randomForestFit <- df_train %>% train(PS_class ~ .,
  method = "rf",
  data = .,
    tuneLength = 365,#365, takes longer to train model with high tunelength
    trControl = trainControl(method = "cv", indexOut = train_index))
randomForestFit
```

Then we want to make a prediction using the test data we set aside earlier.

```{r}
#prediction from RF model
pr_rf <- predict(randomForestFit, df_test)
pr_rf
```

Next we check confusion matrix between prediction and actual type (gold standard) in the test set.
```{r}
#check the confusion matrix
confusionMatrix(pr_rf, reference = df_test$PS_class)
confusionMatrix(pr_rf, reference = df_test$PS_class, mode = "prec_recall")
```
